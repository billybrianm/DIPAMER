{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier # classificadores utilizados\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split # realização da separação do dataset\n",
    "from sklearn.metrics import classification_report # valores de recall e f1-score\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time() # para realizar o cálculo do tempo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_para_raw(imagem, size=(128, 128)):\n",
    "    # reescala a imagem para um tamanho fixo e gera uma lista de \n",
    "    # intensidades de raw pixel em um array\n",
    "    return cv2.resize(imagem, size).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_histograma(image, bins=(8, 8, 8)):\n",
    "    # extrai um histograma de cores de 3 dimensões do espaço HSV\n",
    "    # utilizando a quantidade de bins fornecida \n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "                        [0, 180, 0, 256, 0, 256])\n",
    "    \n",
    "    # realiza a normalização da imagem\n",
    "    cv2.normalize(hist, hist) # alargamento de contraste\n",
    "\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define os argumentos utilizados para execução do programa\n",
    "arg = argparse.ArgumentParser()\n",
    "arg.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "\thelp=\"caminho para o dataset\")\n",
    "arg.add_argument(\"-k\", \"--vizinhos\", type=int, default=1,\n",
    "\thelp=\"# de vizinhos mais proximos para classificacao\")\n",
    "args = vars(arg.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pega as imagens do argumento do dataset para um array\n",
    "print(\"Processando imagens...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "# inicializa os arrays a serem utilizados para preenchimento\n",
    "rawImages = []\n",
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    # carrega a imagem e extrai seu rótulo de classe para o array label\n",
    "    image = cv2.imread(imagePath)\n",
    "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "\n",
    "    # utiliza os algoritmos nas imagens\n",
    "    pixels = img_para_raw(image)\n",
    "    hist = extrair_histograma(image)\n",
    "\n",
    "    # atualiza as matrizes com os valores\n",
    "    rawImages.append(pixels)\n",
    "    features.append(hist)\n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "\n",
    "    # mostra uma atualização a cada 1000 imagens\n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        print(\"[INFO] processados {}/{}\".format(i, len(imagePaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processado = time.time()\n",
    "print(processado - inicio) # mostra o tempo levado na extração de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra informações dos vetores na memória\n",
    "# transforma os arrays em array do NumPy\n",
    "rawImages = np.array(rawImages) # mais rápidos\n",
    "features = np.array(features) # maior performance\n",
    "labels = np.array(labels) # maior funcionalidade\n",
    "print(\"Matriz de pixels: {:.2f}MB\".format(\n",
    "\trawImages.nbytes / (1024 * 1000.0)))\n",
    "print(\"Matriz de caracteristicas: {:.2f}MB\".format(\n",
    "\tfeatures.nbytes / (1024 * 1000.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separa os dados do dataset em 75% para treinamento e 25% para testes\n",
    "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
    "\trawImages, labels, test_size=0.25, random_state=42)\n",
    "(trainFeat, testFeat, trainLabels, testLabels) = train_test_split(\n",
    "\tfeatures, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinamento e avaliação do classificador k-NN em raw pixel\n",
    "print(\"Avaliando precisao em raw pixel...\")\n",
    "modelo = KNeighborsClassifier(n_neighbors=args[\"neighbors\"],n_jobs=-1) # o -1 indica a utilização de todos os cores nos jobs\n",
    "modelo.fit(trainRI, trainRL)\n",
    "acc = modelo.score(testRI, testRL)\n",
    "print(\"Precisao em raw pixel: {:.2f}%\".format(acc * 100))\n",
    "\n",
    "y_pred = model.predict(testRI)\n",
    "print(classification_report(testRL,y_pred)) # relatorio completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treinamento e avaliação do classificador k-NN em histograma\n",
    "print(\"Avaliando precisao em histograma...\")\n",
    "modelo = KNeighborsClassifier(n_neighbors=args[\"neighbors\"],n_jobs=-1)\n",
    "modelo.fit(trainFeat, trainLabels)\n",
    "acc = modelo.score(testFeat, testLabels)\n",
    "print(\"Precisao em histograma: {:.2f}%\".format(acc * 100))\n",
    "\n",
    "y_pred = model.predict(testFeat)\n",
    "print(classification_report(testLabels,y_pred)) # relatorio completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração da Rede Neural\n",
    "modelo = MLPClassifier(solver='adam', #utilização do classificador adam\n",
    "                    learning_rate='constant', #taxa de aprendizagem constante e a mesma para todos os neurônios\n",
    "                    learning_rate_init=1e-3, #aprendizagem inicial de 0.001\n",
    "                    alpha=1e-5, # valor de regularização L2\n",
    "                    hidden_layer_sizes=(5, 2), # definição das camadas escondidas\n",
    "                    max_iter=200, # qtde de epochs\n",
    "                    random_state=1)\n",
    "\n",
    "# Treinamento do modelo\n",
    "modelo.fit(trainFeat, trainLabels)\n",
    "\n",
    "# Previsao utilizando o dataset de testes\n",
    "y_pred = modelo.predict(testFeat)\n",
    "\n",
    "\n",
    "print(\"Precisao:\", metrics.accuracy_score(testLabels, y_pred))\n",
    "\n",
    "print(\"Classificacao %s:\\n%s\\n\"\n",
    "      % (modelo, metrics.classification_report(testLabels, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeamento das Máquinas de Vetores de Suporte\n",
    "modelo = svm.SVC(gamma=0.001, # valor de gamma 0.001\n",
    "                tol=1e-3) # tolerâncica 0.001\n",
    "\n",
    "# Treinamento do modelo\n",
    "modelo.fit(trainFeat, trainLabels)\n",
    "\n",
    "# Previsao utilizando o dataset de testes\n",
    "y_pred = modelo.predict(testFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da Árvore de decisões\n",
    "modelo = tree.DecisionTreeClassifier(min_samples_split=2, # minimo necessario para se dividir um nó interno\n",
    "                                    max_depth=None, # se expandir até ficar pura\n",
    "                                    min_samples_leaf=1) # não divide se não deixar no mínimo uma folha de cada lado\n",
    "\n",
    "#Treinamento do modelo\n",
    "modelo.fit(trainFeat, trainLabels)\n",
    "\n",
    "#Previsao utilizando o dataset de testes\n",
    "y_pred = modelo.predict(testFeat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
